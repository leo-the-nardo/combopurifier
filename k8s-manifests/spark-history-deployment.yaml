apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-history-server-config
  namespace: spark-jobs
  labels:
    app: spark-history-server
data:
  spark-defaults.conf: |
    spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.eventLog.enabled=true
    spark.history.fs.logDirectory=s3a://logs/spark-history
    spark.eventLog.dir=s3a://logs/spark-history
    spark.hadoop.fs.s3a.endpoint=http://minio.minio-dev.svc.cluster.local:9000
    spark.hadoop.fs.s3a.fast.upload=true
    spark.hadoop.fs.s3a.path.style.access=true
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-history-server
  namespace: spark-jobs
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-history-server
  template:
    metadata:
      labels:
        app: spark-history-server
    spec:
      containers:
        - name: spark-history-server
#          image: cloudificando/spark-history:aws-gcp-3.5.0
          image: cloudificando/spark-history:aws-gcp-dataflink-3.5.0
          imagePullPolicy: Always
          args:
            - history-server
          ports:
            - name: http
              protocol: TCP
              containerPort: 18080
          readinessProbe:
            timeoutSeconds: 4
            httpGet:
              path: /
              port: http
          livenessProbe:
            timeoutSeconds: 4
            httpGet:
              path: /
              port: http
          env:
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-onprem-combopurifier
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-onprem-combopurifier
                  key: AWS_SECRET_ACCESS_KEY
            - name: AWS_REGION
              valueFrom:
                secretKeyRef:
                  name: s3-onprem-combopurifier
                  key: AWS_REGION
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2.5Gi"
              cpu: "1"
          volumeMounts:
            - name: spark-history-server-conf
              mountPath: /opt/spark/conf
            # Add any additional volume mounts here
      volumes:
        - name: spark-history-server-conf
          configMap:
            name: spark-history-server-config  # ConfigMap name for Spark configs

---
apiVersion: v1
kind: Service
metadata:
  name: spark-history-server
  namespace: spark-jobs
spec:
  type: ClusterIP  # Use LoadBalancer or NodePort if external access is needed
  ports:
    - port: 18080
      targetPort: 18080
      protocol: TCP
      name: http
  selector:
    app: spark-history-server
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: spark-history-ui
  namespace: gateway
  annotations:
    konghq.com/strip-path: "true"
spec:
  parentRefs:
    - name: kong
      namespace: gateway
  hostnames:
    - spark.cloudificando.corp  # Hostname for UI
  rules:
    - matches:
        - path:
            type: PathPrefix
            value: /
      backendRefs:
        - name: spark-history-server
          port: 18080  # UI port
          kind: Service
          namespace: spark-jobs
---
apiVersion: gateway.networking.k8s.io/v1beta1
kind: ReferenceGrant
metadata:
  name: spark-history
  namespace: spark-jobs
spec:
  from:
    - group: gateway.networking.k8s.io
      kind: HTTPRoute
      namespace: gateway
  to:
    - group: ""
      kind: Service
